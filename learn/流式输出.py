#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""æµå¼è¾“å‡º - LangGraphæµå¼å¤„ç†ä¸å®æ—¶åé¦ˆç¤ºä¾‹

WHY - è®¾è®¡æ€è·¯:
1. åœ¨AIç³»ç»Ÿä¸­ï¼Œå®æ—¶åé¦ˆå¯¹ç”¨æˆ·ä½“éªŒè‡³å…³é‡è¦ï¼Œè€Œä¸æ˜¯è®©ç”¨æˆ·ç­‰å¾…å®Œæ•´ç»“æœ
2. ä¼ ç»Ÿçš„å¼‚æ­¥æ¨¡å¼ä¸‹ï¼Œç”¨æˆ·éœ€è¦ç­‰å¾…æ•´ä¸ªå¤„ç†å®Œæˆæ‰èƒ½è·å¾—ç»“æœ
3. æµå¼è¾“å‡ºå¯ä»¥å±•ç¤ºæ€è€ƒè¿‡ç¨‹ã€è¿›åº¦æ›´æ–°å’Œé€æ­¥ç”Ÿæˆï¼Œå¢å¼ºäº¤äº’æ€§
4. å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œç”¨æˆ·éœ€è¦äº†è§£å¤„ç†è¿›åº¦ä»¥å‡å°‘ç­‰å¾…ç„¦è™‘

HOW - å®ç°æ–¹å¼:
1. ä½¿ç”¨LangGraphçš„stream APIä»£æ›¿æ ‡å‡†invoke
2. è®¾è®¡åŒ…å«çŠ¶æ€è·Ÿè¸ªå­—æ®µçš„çŠ¶æ€ç»“æ„(StreamState)
3. å®ç°ä¸åŒç²’åº¦çš„æµå¼å¤„ç†:
   - çŠ¶æ€çº§æµå¼è¾“å‡º: æ¯æ¬¡çŠ¶æ€æ›´æ–°æ—¶è¿”å›å®Œæ•´çŠ¶æ€
   - äº‹ä»¶çº§æµå¼è¾“å‡º: æ¯æ¬¡èŠ‚ç‚¹æ‰§è¡Œæ—¶è¿”å›äº‹ä»¶é€šçŸ¥
   - å­—ç¬¦çº§æµå¼è¾“å‡º: ç›´æ¥ä»LLMè·å–é€ä¸ªä»¤ç‰Œ
4. ä½¿ç”¨å›è°ƒç³»ç»Ÿè·å–æ›´è¯¦ç»†çš„æ‰§è¡ŒæŒ‡æ ‡å’Œæ€§èƒ½æ•°æ®

WHAT - åŠŸèƒ½ä½œç”¨:
æœ¬ç¤ºä¾‹æ¼”ç¤ºäº†LangGraphä¸­çš„å¤šç§æµå¼å¤„ç†æ¨¡å¼ï¼Œæä¾›å››ä¸ªä¸»è¦ç¤ºä¾‹:
1. åŸºæœ¬æµå¼å¤„ç†: å±•ç¤ºå¦‚ä½•è·å–çŠ¶æ€æ›´æ–°æµ
2. é«˜çº§æµå¼å¤„ç†: å±•ç¤ºå¦‚ä½•å¤„ç†äº‹ä»¶æµå’Œè¯¦ç»†å…ƒæ•°æ®
3. å­—ç¬¦çº§æµå¼è¾“å‡º: å±•ç¤ºå¦‚ä½•å®ç°æ›´ç»†ç²’åº¦çš„è¾“å‡º
4. å›è°ƒä¸ç›‘æ§: å±•ç¤ºå¦‚ä½•è·Ÿè¸ªå›¾æ‰§è¡Œè¿‡ç¨‹çš„è¯¦ç»†ä¿¡æ¯

è¿™äº›ç¤ºä¾‹æ¶µç›–äº†ä»ç®€å•åˆ°å¤æ‚çš„æµå¼å¤„ç†åœºæ™¯ï¼Œé€‚ç”¨äºæ„å»ºå…·æœ‰è‰¯å¥½ç”¨æˆ·ä½“éªŒçš„AIåº”ç”¨ã€‚
"""

from typing import TypedDict, List, Dict, Any, Optional, Union, Literal
import time
import json
from datetime import datetime

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.llms import Ollama
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langgraph.graph import StateGraph, END
from langchain.callbacks import BaseCallbackHandler

# ===========================================================
# ç¬¬1éƒ¨åˆ†: çŠ¶æ€å®šä¹‰
# ===========================================================

class StreamState(TypedDict):
    """æµå¼å¤„ç†çŠ¶æ€å®šä¹‰
    
    WHY - è®¾è®¡æ€è·¯:
    1. åœ¨æµå¼å¤„ç†ä¸­ï¼Œæˆ‘ä»¬éœ€è¦è¿½è¸ªä¸ä»…æ˜¯æœ€ç»ˆç»“æœï¼Œè¿˜åŒ…æ‹¬ä¸­é—´ç”Ÿæˆè¿‡ç¨‹
    2. ä¸ºäº†æ”¯æŒå®æ—¶è¿›åº¦æ˜¾ç¤ºï¼Œéœ€è¦è®°å½•å®Œæˆç™¾åˆ†æ¯”
    3. ç”¨æˆ·ä½“éªŒè¦æ±‚æˆ‘ä»¬èƒ½å¤Ÿæµ‹é‡å’Œå±•ç¤ºå“åº”ç”Ÿæˆçš„æ—¶é—´
    4. æµå¼å¤„ç†éœ€è¦åŒºåˆ†å†…éƒ¨æ€è€ƒè¿‡ç¨‹å’Œå‘ç”¨æˆ·å±•ç¤ºçš„æœ€ç»ˆå›å¤
    
    HOW - å®ç°æ–¹å¼:
    é€šè¿‡TypedDictå®šä¹‰å¸¦ç±»å‹æç¤ºçš„çŠ¶æ€ç»“æ„ï¼ŒåŒ…å«:
    - æ ‡å‡†çš„æ¶ˆæ¯å†å²è®°å½•å­—æ®µ
    - ä¸“é—¨çš„å½“å‰å“åº”å­—æ®µï¼Œå¯å®æ—¶æ›´æ–°
    - æ€è€ƒè¿‡ç¨‹å­—æ®µï¼Œå­˜å‚¨LLMçš„å†…éƒ¨æ¨ç†ä½†ä¸ç›´æ¥å±•ç¤ºç»™ç”¨æˆ·
    - è¿›åº¦è·Ÿè¸ªå­—æ®µï¼Œç”¨äºUIè¿›åº¦æ¡
    - æ—¶é—´æˆ³å­—æ®µï¼Œç”¨äºæ€§èƒ½æµ‹é‡
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æä¾›ä¸€ä¸ªå®Œæ•´çš„çŠ¶æ€å®¹å™¨ï¼Œæ‰¿è½½æµå¼ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å„ç±»æ•°æ®ï¼Œ
    ä½¿å¾—æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹å˜å¾—å¯è§‚å¯Ÿã€å¯æµ‹é‡ä¸”å¯¹ç”¨æˆ·å‹å¥½
    """
    messages: List[Union[HumanMessage, AIMessage, SystemMessage]]  # æ¶ˆæ¯å†å²
    current_response: Optional[str]  # å½“å‰æ­£åœ¨ç”Ÿæˆçš„å“åº”
    thinking: Optional[str]  # æ€è€ƒè¿‡ç¨‹
    progress: Optional[float]  # ç”Ÿæˆè¿›åº¦ (0-1)
    start_time: Optional[float]  # å¼€å§‹æ—¶é—´æˆ³
    end_time: Optional[float]  # ç»“æŸæ—¶é—´æˆ³

def initialize_state() -> StreamState:
    """åˆå§‹åŒ–çŠ¶æ€
    
    WHY - è®¾è®¡æ€è·¯:
    1. æ¯æ¬¡æµå¼ç”Ÿæˆéœ€è¦ä¸€ä¸ªå¹²å‡€çš„åˆå§‹çŠ¶æ€
    2. ç³»ç»Ÿæç¤ºä¿¡æ¯éœ€è¦é¢„è®¾ï¼Œå®šä¹‰AIåŠ©æ‰‹çš„è¡Œä¸ºæ–¹å¼
    3. æ‰€æœ‰è¿½è¸ªå­—æ®µéœ€è¦åˆå§‹åŒ–ä¸ºç©ºå€¼æˆ–é»˜è®¤å€¼
    
    HOW - å®ç°æ–¹å¼:
    åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µçš„StreamStateå­—å…¸:
    - åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç³»ç»ŸæŒ‡ä»¤
    - å°†å…¶ä»–æ‰€æœ‰è¿½è¸ªå­—æ®µè®¾ä¸ºNone
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æä¾›ä¸€ä¸ªä¸€è‡´çš„èµ·ç‚¹ï¼Œç¡®ä¿æ¯æ¬¡æµå¼å¤„ç†å¼€å§‹æ—¶çŠ¶æ€å¹²å‡€ä¸”å¯é¢„æµ‹ï¼Œ
    é¿å…ä¸Šä¸€æ¬¡ç”Ÿæˆçš„æ®‹ç•™æ•°æ®å½±å“æ–°çš„ç”Ÿæˆè¿‡ç¨‹
    """
    return {
        "messages": [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œæ“…é•¿æä¾›è¯¦å°½çš„ä¿¡æ¯ã€‚")
        ],
        "current_response": None,
        "thinking": None,
        "progress": None,
        "start_time": None,
        "end_time": None
    }

# ===========================================================
# ç¬¬2éƒ¨åˆ†: é…ç½®LLM
# ===========================================================

# å°è¯•ä½¿ç”¨Ollamaæœ¬åœ°æ¨¡å‹ï¼Œå¦‚æœä¸å¯ç”¨ï¼Œæ‰“å°æç¤ºä¿¡æ¯
try:
    llm = Ollama(model="llama3", temperature=0.7)
    print("æˆåŠŸè¿æ¥åˆ°Ollamaæ¨¡å‹")
except:
    print("è­¦å‘Š: æ— æ³•è¿æ¥åˆ°Ollamaæ¨¡å‹ï¼Œè¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ")
    print("ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨Ollamaå¹¶æ‹‰å–æ¨¡å‹:")
    print("  1. å¯åŠ¨OllamaæœåŠ¡")
    print("  2. æ‰§è¡Œ: ollama pull llama3")
    
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹ŸLLMç”¨äºæ¼”ç¤º
    class MockLLM:
        def invoke(self, prompt, **kwargs):
            print(f"æ¨¡æ‹ŸLLMæ¥æ”¶åˆ°æç¤º: {prompt[:50]}...")
            return "è¿™æ˜¯æ¨¡æ‹ŸLLMçš„å“åº”ï¼Œç”¨äºæ¼”ç¤ºæµå¼è¾“å‡ºåŠŸèƒ½ã€‚å®é™…ä½¿ç”¨æ—¶ï¼Œè¿™é‡Œä¼šæ˜¯çœŸå®æ¨¡å‹çš„è¾“å‡ºã€‚"
        
        def stream(self, prompt, **kwargs):
            print(f"æ¨¡æ‹ŸLLMå¼€å§‹æµå¼è¾“å‡º...")
            response = "è¿™æ˜¯æ¨¡æ‹ŸLLMçš„å“åº”ï¼Œç”¨äºæ¼”ç¤ºæµå¼è¾“å‡ºåŠŸèƒ½ã€‚å®é™…ä½¿ç”¨æ—¶ï¼Œè¿™é‡Œä¼šæ˜¯çœŸå®æ¨¡å‹çš„è¾“å‡ºã€‚"
            for word in response.split():
                time.sleep(0.1)  # æ¨¡æ‹Ÿç”Ÿæˆå»¶è¿Ÿ
                yield word + " "
    
    llm = MockLLM()

# ===========================================================
# ç¬¬3éƒ¨åˆ†: èŠ‚ç‚¹å‡½æ•°å®šä¹‰
# ===========================================================

def start_generation(state: StreamState) -> StreamState:
    """å¼€å§‹ç”Ÿæˆæµç¨‹ï¼Œè®°å½•èµ·å§‹æ—¶é—´
    
    WHY - è®¾è®¡æ€è·¯:
    1. æµå¼ç”Ÿæˆéœ€è¦ä¸€ä¸ªæ˜ç¡®çš„èµ·ç‚¹ï¼Œç”¨äºåç»­è®¡æ—¶å’Œè¿›åº¦è·Ÿè¸ª
    2. ç”¨æˆ·éœ€è¦çŸ¥é“ç”Ÿæˆè¿‡ç¨‹å·²ç»å¼€å§‹
    3. ä¸ºäº†å‡†ç¡®è®¡ç®—æ€»ç”Ÿæˆæ—¶é—´ï¼Œéœ€è¦è®°å½•ç²¾ç¡®çš„å¼€å§‹æ—¶é—´æˆ³
    
    HOW - å®ç°æ–¹å¼:
    æ¥æ”¶å½“å‰çŠ¶æ€ï¼Œç„¶å:
    - è®°å½•å½“å‰æ—¶é—´ä½œä¸ºå¼€å§‹æ—¶é—´æˆ³
    - åˆå§‹åŒ–è¿›åº¦ä¸º0.0ï¼Œè¡¨ç¤ºåˆšåˆšå¼€å§‹
    - ä¿æŒçŠ¶æ€çš„å…¶ä»–éƒ¨åˆ†ä¸å˜
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æ ‡è®°ç”Ÿæˆè¿‡ç¨‹çš„å¼€å§‹ç‚¹ï¼Œåˆå§‹åŒ–è¿›åº¦è·Ÿè¸ªï¼Œä¸ºåç»­çš„è¿›åº¦æ›´æ–°å’Œ
    æ€§èƒ½æµ‹é‡æä¾›åŸºå‡†ç‚¹
    """
    print("ğŸ•’ å¼€å§‹ç”Ÿæˆ...")
    return {
        **state,
        "start_time": time.time(),
        "progress": 0.0
    }

def generate_thinking(state: StreamState) -> StreamState:
    """ç”Ÿæˆæ€è€ƒè¿‡ç¨‹ï¼ˆä¸ç›´æ¥å¯è§ç»™ç”¨æˆ·ï¼‰
    
    WHY - è®¾è®¡æ€è·¯:
    1. é«˜è´¨é‡å›å¤éœ€è¦å…ˆè¿›è¡Œæ·±å…¥æ€è€ƒï¼Œç„¶åå†ç»„ç»‡å›å¤
    2. å†…éƒ¨æ€è€ƒè¿‡ç¨‹å¯¹è°ƒè¯•å’Œåˆ†æéå¸¸æœ‰ä»·å€¼ï¼Œä½†ä¸åº”ç›´æ¥å±•ç¤ºç»™ç”¨æˆ·
    3. è®©AIå…ˆæ€è€ƒå¯ä»¥æé«˜æœ€ç»ˆå›å¤çš„è´¨é‡å’Œç›¸å…³æ€§
    4. æ€è€ƒè¿‡ç¨‹å¯ä»¥ç”¨äºæ˜¾ç¤ºéƒ¨åˆ†è¿›åº¦ï¼Œæé«˜ç”¨æˆ·ç­‰å¾…ä½“éªŒ
    
    HOW - å®ç°æ–¹å¼:
    1. æ£€æŸ¥çŠ¶æ€ä¸­æ˜¯å¦æœ‰ç”¨æˆ·æ¶ˆæ¯
    2. æå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å†…å®¹
    3. ä½¿ç”¨ä¸“é—¨æç¤ºè®©LLMç”Ÿæˆæ€è€ƒè¿‡ç¨‹
    4. é€šè¿‡é“¾å¼è°ƒç”¨ç”Ÿæˆæ€è€ƒå†…å®¹
    5. æ›´æ–°çŠ¶æ€çš„æ€è€ƒå­—æ®µå’Œè¿›åº¦
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    ç”ŸæˆLLMå†…éƒ¨çš„åˆ†æå’Œæ¨ç†è¿‡ç¨‹ï¼Œä¸ºæœ€ç»ˆå›å¤æä¾›åŸºç¡€ï¼Œ
    åŒæ—¶æ›´æ–°è¿›åº¦åˆ°çº¦30%ï¼Œè¡¨æ˜ç”Ÿæˆå·¥ä½œæ­£åœ¨è¿›è¡Œ
    """
    print("ğŸ§  ç”Ÿæˆæ€è€ƒè¿‡ç¨‹...")
    
    # è·å–æ¶ˆæ¯å†å²
    messages = state["messages"]
    if not any(isinstance(msg, HumanMessage) for msg in messages):
        return {**state, "thinking": "æ²¡æœ‰ç”¨æˆ·è¾“å…¥ï¼Œæ— æ³•ç”Ÿæˆæ€è€ƒè¿‡ç¨‹"}
    
    # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    last_user_msg = next((msg.content for msg in reversed(messages) 
                         if isinstance(msg, HumanMessage)), "")
    
    # ä½¿ç”¨LLMç”Ÿæˆæ€è€ƒè¿‡ç¨‹
    prompt = ChatPromptTemplate.from_messages([
        ("system", "åˆ†æä»¥ä¸‹ç”¨æˆ·é—®é¢˜ï¼Œæ€è€ƒå¦‚ä½•å›ç­”ï¼ˆè¿™ä¸ªæ€è€ƒè¿‡ç¨‹ä¸ä¼šå±•ç¤ºç»™ç”¨æˆ·ï¼‰:"),
        ("user", "{input}")
    ])
    
    thinking_chain = prompt | llm | StrOutputParser()
    thinking = thinking_chain.invoke({"input": last_user_msg})
    
    # æ›´æ–°è¿›åº¦
    return {
        **state,
        "thinking": thinking,
        "progress": 0.3  # æ€è€ƒè¿‡ç¨‹å æ€»è¿›åº¦çš„30%
    }

def generate_response(state: StreamState) -> StreamState:
    """ç”Ÿæˆæœ€ç»ˆå›å¤
    
    WHY - è®¾è®¡æ€è·¯:
    1. æœ‰äº†æ€è€ƒè¿‡ç¨‹åï¼Œéœ€è¦ç”Ÿæˆä¸€ä¸ªç²¾ç‚¼çš„ã€é¢å‘ç”¨æˆ·çš„å›å¤
    2. å›å¤åº”è¯¥åˆ©ç”¨æ€è€ƒè¿‡ç¨‹çš„æ´è§ï¼Œä½†ä¸ç›´æ¥æš´éœ²æ€è€ƒç»†èŠ‚
    3. å›å¤éœ€è¦ä¿å­˜åˆ°æ¶ˆæ¯å†å²ä¸­ï¼Œä»¥æ”¯æŒå¤šè½®å¯¹è¯
    4. ç”Ÿæˆå®Œæˆåéœ€è¦æ ‡è®°æ•´ä¸ªæµç¨‹å·²ç»“æŸ
    
    HOW - å®ç°æ–¹å¼:
    1. ä»çŠ¶æ€ä¸­è·å–æ¶ˆæ¯å†å²å’Œæ€è€ƒè¿‡ç¨‹
    2. ä½¿ç”¨ç‰¹æ®Šæç¤ºï¼ŒæŒ‡å¯¼LLMåŸºäºæ€è€ƒè¿‡ç¨‹ç”Ÿæˆå›å¤
    3. åˆ›å»ºå“åº”é“¾å¹¶è°ƒç”¨LLMç”Ÿæˆå›å¤
    4. å°†å›å¤æ·»åŠ åˆ°æ¶ˆæ¯å†å²
    5. æ›´æ–°çŠ¶æ€ï¼Œæ ‡è®°è¿›åº¦ä¸º100%å¹¶è®°å½•ç»“æŸæ—¶é—´
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    åˆ©ç”¨å‰é¢ç”Ÿæˆçš„æ€è€ƒå†…å®¹ï¼Œåˆ›å»ºä¸€ä¸ªé«˜è´¨é‡çš„ç”¨æˆ·å¯è§å›å¤ï¼Œ
    æ›´æ–°å¯¹è¯å†å²ï¼Œå¹¶æ ‡è®°ç”Ÿæˆè¿‡ç¨‹å®Œæˆ
    """
    print("ğŸ’¬ ç”Ÿæˆå›å¤...")
    
    # è·å–æ¶ˆæ¯å†å²å’Œæ€è€ƒè¿‡ç¨‹
    messages = state["messages"]
    thinking = state.get("thinking", "")
    
    if not any(isinstance(msg, HumanMessage) for msg in messages):
        return {**state, "current_response": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"}
    
    # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    last_user_msg = next((msg.content for msg in reversed(messages) 
                         if isinstance(msg, HumanMessage)), "")
    
    # ä½¿ç”¨å¸¦æ€è€ƒè¿‡ç¨‹çš„æç¤ºæ¥ç”Ÿæˆå›å¤
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚ä½¿ç”¨ä»¥ä¸‹æ€è€ƒè¿‡ç¨‹æ¥å¸®åŠ©å›ç­”ï¼Œä½†ä¸è¦åœ¨å›å¤ä¸­æåŠè¿™ä¸ªæ€è€ƒè¿‡ç¨‹:\n{thinking}"),
        ("user", "{input}")
    ])
    
    response_chain = prompt | llm | StrOutputParser()
    response = response_chain.invoke({
        "thinking": thinking,
        "input": last_user_msg
    })
    
    # æ›´æ–°çŠ¶æ€
    new_messages = messages.copy()
    new_messages.append(AIMessage(content=response))
    
    return {
        **state,
        "messages": new_messages,
        "current_response": response,
        "progress": 1.0,  # å®Œæˆç”Ÿæˆ
        "end_time": time.time()
    }

def update_progress(state: StreamState) -> StreamState:
    """æ›´æ–°è¿›åº¦ä¿¡æ¯
    
    WHY - è®¾è®¡æ€è·¯:
    1. å³ä½¿æ²¡æœ‰å®è´¨æ€§è¿›å±•ï¼Œç”¨æˆ·ä¹Ÿéœ€è¦çœ‹åˆ°è¿›åº¦å˜åŒ–ï¼Œä»¥ç¡®è®¤ç³»ç»Ÿä»åœ¨å·¥ä½œ
    2. æ¸è¿›å¼æ›´æ–°è¿›åº¦å¯ä»¥æé«˜ç”¨æˆ·ç­‰å¾…ä½“éªŒï¼Œå‡å°‘ç„¦è™‘æ„Ÿ
    3. ç»™ç”¨æˆ·æä¾›ç²¾ç»†çš„è¿›åº¦åé¦ˆæ¯”ç®€å•çš„"æ­£åœ¨å¤„ç†"æ›´æœ‰ä»·å€¼
    
    HOW - å®ç°æ–¹å¼:
    1. è·å–å½“å‰è¿›åº¦å€¼
    2. å¦‚æœæœªè¾¾åˆ°å®ŒæˆçŠ¶æ€ï¼Œåˆ™å¢åŠ ä¸€ä¸ªå°çš„è¿›åº¦é‡
    3. é™åˆ¶æœ€å¤§è¿›åº¦åˆ°90%ï¼Œé¢„ç•™10%ç»™æœ€ç»ˆå®Œæˆæ­¥éª¤
    4. è¿”å›å¸¦æœ‰æ›´æ–°è¿›åº¦çš„çŠ¶æ€
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æ¨¡æ‹Ÿç»†ç²’åº¦çš„è¿›åº¦æ›´æ–°ï¼Œåœ¨å®é™…è®¡ç®—è¿›è¡ŒæœŸé—´ç»™ç”¨æˆ·æä¾›è§†è§‰åé¦ˆï¼Œ
    ä½¿é•¿æ—¶é—´è¿è¡Œçš„æ“ä½œæ˜¾å¾—æ›´åŠ å¹³æ»‘å’Œå¯é¢„æµ‹
    """
    current_progress = state.get("progress", 0)
    
    # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
    if current_progress < 1.0:
        new_progress = min(current_progress + 0.1, 0.9)  # æœ€å¤šæ›´æ–°åˆ°90%ï¼Œç•™10%ç»™æœ€ç»ˆå®Œæˆ
        print(f"ğŸ“Š è¿›åº¦æ›´æ–°: {new_progress:.1f}")
        
        return {
            **state,
            "progress": new_progress
        }
    
    return state

# ===========================================================
# ç¬¬4éƒ¨åˆ†: åˆ›å»ºåŸºæœ¬å›¾ç»“æ„
# ===========================================================

def create_basic_graph():
    """åˆ›å»ºåŸºæœ¬æµå¼å¤„ç†å›¾
    
    WHY - è®¾è®¡æ€è·¯:
    1. éœ€è¦ä¸€ä¸ªç®€å•ä¸”å¯é‡ç”¨çš„æµå¼å¤„ç†å·¥ä½œæµç»“æ„
    2. æµç¨‹éœ€è¦åŒ…å«ç”Ÿæˆçš„å„ä¸ªå…³é”®é˜¶æ®µï¼ˆå¼€å§‹ã€æ€è€ƒã€å›å¤ï¼‰
    3. èŠ‚ç‚¹å’Œè¾¹éœ€è¦æœ‰æ˜ç¡®çš„ç»„ç»‡ï¼Œä¾¿äºç†è§£å’Œä¿®æ”¹
    
    HOW - å®ç°æ–¹å¼:
    1. åˆ›å»ºä¸€ä¸ªä½¿ç”¨StreamStateç±»å‹çš„å›¾
    2. æ·»åŠ ä¸‰ä¸ªä¸»è¦èŠ‚ç‚¹ï¼Œä»£è¡¨ç”Ÿæˆè¿‡ç¨‹çš„ä¸‰ä¸ªé˜¶æ®µ
    3. å®šä¹‰èŠ‚ç‚¹é—´çš„çº¿æ€§æµåŠ¨è·¯å¾„
    4. è®¾ç½®workflowçš„å…¥å£ç‚¹
    5. è¿”å›ç¼–è¯‘åçš„å›¾ï¼Œä½¿å…¶å¯æ‰§è¡Œ
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æä¾›ä¸€ä¸ªåŸºç¡€çš„çº¿æ€§æµå¼å¤„ç†å›¾ç»“æ„ï¼Œå®ç°ä»å¼€å§‹åˆ°æ€è€ƒå†åˆ°å›å¤çš„
    åŸºæœ¬æµç¨‹ï¼Œä¸ºæµå¼è¾“å‡ºåŠŸèƒ½æä¾›éª¨æ¶
    """
    # åˆ›å»ºå›¾å®ä¾‹
    workflow = StateGraph(StreamState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("start", start_generation)
    workflow.add_node("thinking", generate_thinking)
    workflow.add_node("respond", generate_response)
    
    # æ·»åŠ è¾¹
    workflow.add_edge("start", "thinking")
    workflow.add_edge("thinking", "respond")
    workflow.add_edge("respond", END)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("start")
    
    # ç¼–è¯‘å›¾
    return workflow.compile()

# ===========================================================
# ç¬¬5éƒ¨åˆ†: æµå¼è¾“å‡ºä¸äº‹ä»¶å¤„ç†
# ===========================================================

def run_basic_stream_example():
    """è¿è¡ŒåŸºæœ¬æµå¼å¤„ç†ç¤ºä¾‹
    
    WHY - è®¾è®¡æ€è·¯:
    1. éœ€è¦å±•ç¤ºæµå¼å¤„ç†çš„åŸºæœ¬å·¥ä½œæ–¹å¼å’ŒAPIä½¿ç”¨
    2. ç”¨æˆ·éœ€è¦ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹æ¥ç†è§£æµå¼è¾“å‡ºå’Œæ™®é€šè¾“å‡ºçš„åŒºåˆ«
    3. å®ä¾‹åº”è¯¥å±•ç¤ºå¦‚ä½•è·å–å’Œä½¿ç”¨æµå¼çŠ¶æ€æ›´æ–°
    
    HOW - å®ç°æ–¹å¼:
    1. åˆ›å»ºåŸºæœ¬æµç¨‹å›¾
    2. å‡†å¤‡åˆå§‹çŠ¶æ€ï¼ŒåŒ…å«ä¸€ä¸ªç¤ºä¾‹ç”¨æˆ·æŸ¥è¯¢
    3. ä½¿ç”¨streamæ–¹æ³•ä»£æ›¿invokeï¼ŒæŒ‡å®šstream_modeä¸º"values"
    4. è¿­ä»£äº‹ä»¶æµï¼Œæå–å¹¶å±•ç¤ºå…³é”®çŠ¶æ€å­—æ®µ
    5. å±•ç¤ºç”Ÿæˆè¿‡ç¨‹ä¸­çš„è¿›åº¦ã€æ€è€ƒå’Œæœ€ç»ˆå“åº”
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æä¾›ä¸€ä¸ªå®Œæ•´çš„æµå¼å¤„ç†æ¼”ç¤ºï¼Œå±•ç¤ºLangGraphä¸­stream APIçš„ä½¿ç”¨æ–¹æ³•ï¼Œ
    å¹¶å‘ˆç°æµå¼å¤„ç†è¿‡ç¨‹ä¸­çš„å„ä¸ªçŠ¶æ€æ›´æ–°
    """
    print("\n===== åŸºæœ¬æµå¼å¤„ç†ç¤ºä¾‹ =====")
    
    # åˆ›å»ºå›¾
    graph = create_basic_graph()
    
    # åˆå§‹åŒ–çŠ¶æ€
    state = initialize_state()
    state["messages"].append(HumanMessage(content="ä»‹ç»ä¸€ä¸‹ä¸­å›½çš„å››å¤§å‘æ˜"))
    
    # é…ç½®
    config = {"recursion_limit": 25}
    
    print("\nå¼€å§‹æµå¼å¤„ç†...")
    # ä½¿ç”¨streamæ–¹æ³•ï¼Œè€Œä¸æ˜¯invoke
    events = graph.stream(
        state,
        config,
        stream_mode="values"  # æµå¼è¿”å›çŠ¶æ€å€¼
    )
    
    # å¤„ç†äº‹ä»¶æµ
    for i, event in enumerate(events):
        print(f"\näº‹ä»¶ #{i+1}:")
        
        if "progress" in event:
            print(f"è¿›åº¦: {event['progress']:.1%}")
        
        if "thinking" in event and event["thinking"]:
            print(f"æ€è€ƒ: {event['thinking'][:50]}..." if event["thinking"] else "")
        
        if "current_response" in event and event["current_response"]:
            print(f"å“åº”: {event['current_response'][:50]}..." if event["current_response"] else "")
        
        if "end_time" in event and event["end_time"]:
            start = event.get("start_time", 0)
            end = event["end_time"]
            if start and end:
                print(f"ç”Ÿæˆè€—æ—¶: {end - start:.2f}ç§’")

# ===========================================================
# ç¬¬6éƒ¨åˆ†: é«˜çº§æµå¼å¤„ç†ä¸æ ¼å¼åŒ–
# ===========================================================

def create_advanced_stream_graph():
    """åˆ›å»ºé«˜çº§æµå¼å¤„ç†å›¾ï¼ŒåŒ…å«è¿›åº¦æ›´æ–°èŠ‚ç‚¹
    
    WHY - è®¾è®¡æ€è·¯:
    1. åŸºæœ¬å›¾ç¼ºä¹ä¸­é—´è¿›åº¦æ›´æ–°ï¼Œè®©ç”¨æˆ·ä½“éªŒä¸å¤Ÿå¹³æ»‘
    2. åœ¨æ€è€ƒå’Œå›å¤ä¹‹é—´éœ€è¦æ›´ç»†ç²’åº¦çš„è¿›åº¦åé¦ˆ
    3. è¿›åº¦æ›´æ–°å¯ä»¥å‡å°‘ç”¨æˆ·çš„ç­‰å¾…ç„¦è™‘
    
    HOW - å®ç°æ–¹å¼:
    1. åˆ›å»ºä¸€ä¸ªä½¿ç”¨StreamStateç±»å‹çš„å›¾
    2. é™¤äº†åŸºæœ¬èŠ‚ç‚¹å¤–ï¼Œé¢å¤–æ·»åŠ è¿›åº¦æ›´æ–°èŠ‚ç‚¹
    3. è°ƒæ•´è¾¹ï¼Œä½¿æµç¨‹ç»è¿‡è¿›åº¦æ›´æ–°èŠ‚ç‚¹
    4. è®¾ç½®workflowçš„å…¥å£ç‚¹
    5. è¿”å›ç¼–è¯‘åçš„å›¾ï¼Œä½¿å…¶å¯æ‰§è¡Œ
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æä¾›ä¸€ä¸ªå¢å¼ºç‰ˆçš„æµå¼å¤„ç†å›¾ï¼Œæ·»åŠ äº†é¢å¤–çš„è¿›åº¦æ›´æ–°ç¯èŠ‚ï¼Œ
    ä¼˜åŒ–äº†ç”¨æˆ·ç­‰å¾…ä½“éªŒï¼Œä½¿è¿›åº¦å±•ç¤ºæ›´å¹³æ»‘
    """
    # åˆ›å»ºå›¾å®ä¾‹
    workflow = StateGraph(StreamState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("start", start_generation)
    workflow.add_node("thinking", generate_thinking)
    workflow.add_node("update_progress", update_progress)  # æ·»åŠ è¿›åº¦æ›´æ–°èŠ‚ç‚¹
    workflow.add_node("respond", generate_response)
    
    # æ·»åŠ è¾¹
    workflow.add_edge("start", "thinking")
    workflow.add_edge("thinking", "update_progress")
    workflow.add_edge("update_progress", "respond")
    workflow.add_edge("respond", END)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("start")
    
    # ç¼–è¯‘å›¾
    return workflow.compile()

def run_advanced_stream_example():
    """è¿è¡Œé«˜çº§æµå¼å¤„ç†ç¤ºä¾‹
    
    WHY - è®¾è®¡æ€è·¯:
    1. éœ€è¦å±•ç¤ºæ›´å¤æ‚çš„æµå¼å¤„ç†æ¨¡å¼å’Œæ›´ç²¾ç»†çš„äº‹ä»¶ç›‘å¬
    2. åŸºæœ¬ç¤ºä¾‹åªå±•ç¤ºäº†çŠ¶æ€å€¼ï¼Œä½†äº‹ä»¶ç±»å‹å’Œå…ƒæ•°æ®åŒæ ·é‡è¦
    3. ç”¨æˆ·éœ€è¦äº†è§£å¦‚ä½•å¤„ç†ä¸åŒç±»å‹çš„äº‹ä»¶å’ŒçŠ¶æ€æ›´æ–°
    
    HOW - å®ç°æ–¹å¼:
    1. åˆ›å»ºé«˜çº§æµç¨‹å›¾ï¼ˆåŒ…å«è¿›åº¦æ›´æ–°èŠ‚ç‚¹ï¼‰
    2. å‡†å¤‡åˆå§‹çŠ¶æ€ï¼ŒåŒ…å«ä¸€ä¸ªç¤ºä¾‹ç”¨æˆ·æŸ¥è¯¢
    3. ä½¿ç”¨streamæ–¹æ³•ï¼Œä½†æŒ‡å®šstream_modeä¸º"updates"
    4. åŸºäºäº‹ä»¶ç±»å‹ï¼ˆå¼€å§‹ã€ç»“æŸã€é”™è¯¯ï¼‰ä»¥ä¸åŒæ–¹å¼å¤„ç†äº‹ä»¶
    5. å¯¹äº‹ä»¶å†…å®¹è¿›è¡Œæ ¼å¼åŒ–ï¼Œæé«˜å¯è¯»æ€§
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æä¾›ä¸€ä¸ªæ›´é«˜çº§çš„æµå¼å¤„ç†æ¼”ç¤ºï¼Œä¸“æ³¨äºäº‹ä»¶ç±»å‹å’Œäº‹ä»¶å¤„ç†æ¨¡å¼ï¼Œ
    å±•ç¤ºå¦‚ä½•ç›‘å¬èŠ‚ç‚¹æ‰§è¡Œè¿‡ç¨‹å¹¶æå–è¯¦ç»†ä¿¡æ¯
    """
    print("\n===== é«˜çº§æµå¼å¤„ç†ç¤ºä¾‹ =====")
    
    # åˆ›å»ºå›¾
    graph = create_advanced_stream_graph()
    
    # åˆå§‹åŒ–çŠ¶æ€
    state = initialize_state()
    state["messages"].append(HumanMessage(content="è§£é‡Šé‡å­ç‰©ç†çš„åŸºæœ¬åŸç†"))
    
    # é…ç½®
    config = {"recursion_limit": 25}
    
    print("\nå¼€å§‹æµå¼å¤„ç†ï¼Œå¸¦æ ¼å¼åŒ–è¾“å‡º...")
    
    # æµå¼å¤„ç†
    events = graph.stream(
        state,
        config,
        stream_mode="updates"  # åªæµå¼è¿”å›çŠ¶æ€æ›´æ–°
    )
    
    # æ ¼å¼åŒ–äº‹ä»¶è¾“å‡º
    for event in events:
        event_type = event.get("event")
        if event_type == "on_chain_start":
            node_name = event.get("name", "unknown")
            print(f"\nğŸ”„ å¼€å§‹æ‰§è¡ŒèŠ‚ç‚¹: {node_name}")
            
        elif event_type == "on_chain_end":
            node_name = event.get("name", "unknown")
            print(f"âœ… å®ŒæˆèŠ‚ç‚¹: {node_name}")
            
            if "output" in event:
                output = event["output"]
                if isinstance(output, dict):
                    # æå–å¹¶æ ¼å¼åŒ–ç›¸å…³è¾“å‡º
                    if "progress" in output:
                        print(f"ğŸ“ˆ å½“å‰è¿›åº¦: {output['progress']:.1%}")
                    if "thinking" in output and output["thinking"]:
                        print(f"ğŸ§  æ€è€ƒ: {output['thinking'][:100]}..." if len(output['thinking']) > 100 else output['thinking'])
                    if "current_response" in output and output["current_response"]:
                        print(f"ğŸ’¬ å“åº”: {output['current_response']}")
                        
        elif event_type == "on_chain_error":
            error = event.get("error", "æœªçŸ¥é”™è¯¯")
            print(f"âŒ é”™è¯¯: {error}")

# ===========================================================
# ç¬¬7éƒ¨åˆ†: å­—ç¬¦çº§æµå¼è¾“å‡º
# ===========================================================

def create_character_stream_chain():
    """åˆ›å»ºå­—ç¬¦çº§æµå¼è¾“å‡ºå¤„ç†é“¾
    
    WHY - è®¾è®¡æ€è·¯:
    1. çº¯å›¾çº§æµå¼å¤„ç†é€šå¸¸è¿”å›æ•´ä¸ªå¯¹è±¡æˆ–çŠ¶æ€ï¼Œæ— æ³•æä¾›å­—ç¬¦çº§ç»†ç²’åº¦
    2. éœ€è¦ä¸€ä¸ªç‹¬ç«‹äºå›¾çš„æœºåˆ¶ç›´æ¥ä»LLMè·å–æµå¼ä»¤ç‰Œ
    3. éœ€è¦ä¸€ä¸ªç®€å•çš„å¤„ç†æµç¨‹å°†çŠ¶æ€è½¬æ¢ä¸ºé€‚åˆLLMçš„æç¤ºæ ¼å¼
    
    HOW - å®ç°æ–¹å¼:
    1. ä½¿ç”¨RunnablePassthroughä¿ç•™è¾“å…¥çŠ¶æ€
    2. ä½¿ç”¨æ˜ å°„å‡½æ•°ä»è¾“å…¥çŠ¶æ€æå–æ¶ˆæ¯å†å²
    3. ä½¿ç”¨æ ¼å¼åŒ–å‡½æ•°åˆ›å»ºå®Œæ•´çš„æç¤ºæ¨¡æ¿
    4. å°†è¿™äº›æ­¥éª¤é“¾æ¥æˆä¸€ä¸ªå¤„ç†ç®¡é“
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    è¿”å›ä¸€ä¸ªç”¨äºå­—ç¬¦æµå¤„ç†çš„è½»é‡çº§å¤„ç†é“¾ï¼Œè¯¥é“¾å°†çŠ¶æ€å¯¹è±¡è½¬æ¢ä¸º
    LLMå¯ä»¥ç›´æ¥å¤„ç†çš„æç¤ºæ ¼å¼ï¼Œä¾¿äºä½¿ç”¨LLMçš„streamæ–¹æ³•
    """
    # åˆ›å»ºä¸€ä¸ªé“¾ï¼Œå¤„ç†è¾“å…¥å¹¶å‡†å¤‡æç¤º
    chain = (
        RunnablePassthrough() 
        | {
            "messages": lambda x: x["messages"],
            "prompt": lambda x: format_prompt_from_messages(x["messages"])
        }
    )
    return chain

def run_character_stream_example():
    """è¿è¡Œå­—ç¬¦çº§æµå¼è¾“å‡ºç¤ºä¾‹
    
    WHY - è®¾è®¡æ€è·¯:
    1. å›¾çº§æµå¼å¤„ç†ç²’åº¦è¾ƒç²—ï¼Œæ— æ³•å®ç°é€å­—ç¬¦çš„å¹³æ»‘è¾“å‡ºæ•ˆæœ
    2. ç”¨æˆ·æœŸæœ›ç±»ä¼¼ChatGPTé‚£æ ·çš„é€å­—ç¬¦è¾“å‡ºï¼Œä½“éªŒæ›´ä½³
    3. éœ€è¦å±•ç¤ºå¦‚ä½•ç›´æ¥ä½¿ç”¨LLMçš„streamæ–¹æ³•å®ç°ç»†ç²’åº¦è¾“å‡º
    
    HOW - å®ç°æ–¹å¼:
    1. åˆ›å»ºä¸€ä¸ªå¤„ç†é“¾ï¼Œå°†çŠ¶æ€è½¬æ¢ä¸ºé€‚åˆLLMçš„æç¤ºæ ¼å¼
    2. å‡†å¤‡åˆå§‹çŠ¶æ€ï¼ŒåŒ…å«ä¸€ä¸ªç¤ºä¾‹ç”¨æˆ·æŸ¥è¯¢
    3. ç›´æ¥ä½¿ç”¨LLMçš„streamæ–¹æ³•è·å–ä»¤ç‰Œæµ
    4. å®æ—¶æ‰“å°æ¯ä¸ªä»¤ç‰Œï¼Œæ¨¡æ‹Ÿé€å­—è¾“å‡ºæ•ˆæœ
    5. æ”¶é›†å®Œæ•´å“åº”å¹¶æ›´æ–°æœ€ç»ˆçŠ¶æ€
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æä¾›ä¸€ä¸ªå­—ç¬¦çº§æµå¼è¾“å‡ºçš„æ¼”ç¤ºï¼Œå±•ç¤ºå¦‚ä½•å®ç°æ›´ç»†ç²’åº¦ã€æ›´æµç•…çš„
    è¾“å‡ºæ•ˆæœï¼Œæé«˜ç”¨æˆ·äº¤äº’ä½“éªŒ
    """
    print("\n===== å­—ç¬¦çº§æµå¼è¾“å‡ºç¤ºä¾‹ =====")
    
    # åˆå§‹åŒ–çŠ¶æ€
    state = initialize_state()
    state["messages"].append(HumanMessage(content="å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—"))
    
    # åˆ›å»ºé“¾
    chain = create_character_stream_chain()
    
    # è½¬æ¢çŠ¶æ€
    processed_input = chain.invoke(state)
    prompt = processed_input["prompt"]
    
    print("\nå¼€å§‹å­—ç¬¦çº§æµå¼è¾“å‡º...")
    print("ç”¨æˆ·: å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—")
    print("AI: ", end="", flush=True)
    
    # æµå¼è¾“å‡º
    response_tokens = []
    for token in llm.stream(prompt):
        # æ¨¡æ‹Ÿé€å­—ç¬¦è¾“å‡º
        print(token, end="", flush=True)
        response_tokens.append(token)
        time.sleep(0.05)  # æ·»åŠ å»¶è¿Ÿä½¿è¾“å‡ºæ›´æ¸…æ™°å¯è§
    
    # æ”¶é›†å®Œæ•´å“åº”
    full_response = "".join(response_tokens)
    
    # æ›´æ–°çŠ¶æ€
    state["messages"].append(AIMessage(content=full_response))
    state["current_response"] = full_response
    state["progress"] = 1.0
    state["end_time"] = time.time()
    
    print("\n\nâœ… å­—ç¬¦çº§æµå¼è¾“å‡ºå®Œæˆ")

# ===========================================================
# ç¬¬8éƒ¨åˆ†: äº‹ä»¶ç›‘å¬ä¸å›è°ƒ
# ===========================================================

class CustomCallbackHandler(BaseCallbackHandler):
    """è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
    
    WHY - è®¾è®¡æ€è·¯:
    1. éœ€è¦ä¸€ç§æœºåˆ¶æ¥ç›‘æ§å›¾æ‰§è¡Œçš„è¯¦ç»†è¿‡ç¨‹ï¼Œè¶…å‡ºæµå¼çŠ¶æ€æ›´æ–°ä¹‹å¤–
    2. éœ€è¦æ”¶é›†æ€§èƒ½æŒ‡æ ‡å’Œæ‰§è¡Œç»Ÿè®¡ä¿¡æ¯ï¼Œå¦‚è€—æ—¶å’Œtokenä½¿ç”¨é‡
    3. å›è°ƒç³»ç»Ÿæä¾›äº†æ›´çµæ´»çš„é›†æˆç‚¹ï¼Œå¯ä»¥è¿æ¥åˆ°å¤–éƒ¨ç›‘æ§æˆ–æ—¥å¿—ç³»ç»Ÿ
    
    HOW - å®ç°æ–¹å¼:
    1. ç»§æ‰¿BaseCallbackHandleråŸºç±»ï¼Œå®ç°æ ¸å¿ƒå›è°ƒæ–¹æ³•
    2. ç»´æŠ¤å†…éƒ¨çŠ¶æ€æ¥è·Ÿè¸ªæ‰§è¡Œè¿‡ç¨‹çš„å…³é”®æŒ‡æ ‡
    3. æä¾›æ–¹æ³•æ”¶é›†å’Œæ±‡æ€»æ‰§è¡Œä¿¡æ¯
    4. åœ¨å…³é”®äº‹ä»¶ï¼ˆå¼€å§‹ã€ç»“æŸã€é”™è¯¯ï¼‰æ—¶æ•è·ç›¸å…³æ•°æ®
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æä¾›ä¸€ä¸ªå¯æ’æ‹”çš„ç›‘æ§ç»„ä»¶ï¼Œç”¨äºè·Ÿè¸ªå›¾æ‰§è¡Œè¿‡ç¨‹ä¸­çš„å„ç§äº‹ä»¶ï¼Œ
    æ”¶é›†èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´ã€tokenä½¿ç”¨æƒ…å†µå’Œæ­¥éª¤é¡ºåºç­‰å…³é”®æŒ‡æ ‡
    """
    def __init__(self):
        """åˆå§‹åŒ–å›è°ƒå¤„ç†å™¨
        
        åˆå§‹åŒ–å„ç§è®¡æ•°å™¨å’Œè·Ÿè¸ªå˜é‡ï¼Œä¸ºç›‘æ§å›¾æ‰§è¡Œåšå‡†å¤‡
        """
        super().__init__()
        # è·Ÿè¸ªæ‰§è¡Œæ­¥éª¤
        self.steps = 0
        # è®°å½•èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´
        self.node_times = {}
        # è®°å½•èŠ‚ç‚¹å¼€å§‹æ—¶é—´
        self.node_start_times = {}
        # è®°å½•æ€»tokenä½¿ç”¨é‡
        self.total_tokens = 0
    
    def on_chain_start(self, serialized: dict, inputs: dict, **kwargs):
        """å½“é“¾/èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œæ—¶è°ƒç”¨
        
        WHY: éœ€è¦è®°å½•èŠ‚ç‚¹æ‰§è¡Œçš„å¼€å§‹æ—¶é—´ï¼Œä¸ºè®¡ç®—è€—æ—¶åšå‡†å¤‡
        HOW: è·å–èŠ‚ç‚¹åç§°ï¼Œè®°å½•å½“å‰æ—¶é—´æˆ³
        WHAT: è·Ÿè¸ªèŠ‚ç‚¹æ‰§è¡Œçš„èµ·å§‹ç‚¹
        """
        node_name = serialized.get("name", "unknown")
        self.node_start_times[node_name] = time.time()
        print(f">> å¼€å§‹æ‰§è¡Œ: {node_name}")
    
    def on_chain_end(self, outputs: dict, **kwargs):
        """å½“é“¾/èŠ‚ç‚¹æ‰§è¡Œå®Œæˆæ—¶è°ƒç”¨
        
        WHY: éœ€è¦è®¡ç®—èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´ï¼Œè®°å½•è¾“å‡ºä¿¡æ¯ï¼Œå¹¶æ›´æ–°ç»Ÿè®¡æ•°æ®
        HOW: è·å–èŠ‚ç‚¹åç§°ï¼Œè®¡ç®—è€—æ—¶ï¼Œåˆ†æè¾“å‡ºï¼Œæ›´æ–°è®¡æ•°å™¨
        WHAT: è·Ÿè¸ªèŠ‚ç‚¹æ‰§è¡Œçš„å®Œæˆæƒ…å†µåŠå…¶è¾“å‡º
        """
        self.steps += 1
        
        # ä»kwargsä¸­è·å–åºåˆ—åŒ–ä¿¡æ¯
        serialized = kwargs.get("serialized", {})
        node_name = serialized.get("name", "unknown")
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        if node_name in self.node_start_times:
            start_time = self.node_start_times[node_name]
            end_time = time.time()
            execution_time = end_time - start_time
            
            # ç´¯åŠ èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´
            if node_name in self.node_times:
                self.node_times[node_name] += execution_time
            else:
                self.node_times[node_name] = execution_time
            
            print(f"<< å®Œæˆæ‰§è¡Œ: {node_name} (è€—æ—¶: {execution_time:.2f}ç§’)")
            
            # ä¼°ç®—tokenä½¿ç”¨é‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
            if isinstance(outputs, dict) and "thinking" in outputs and outputs["thinking"]:
                # éå¸¸ç²—ç•¥çš„ä¼°è®¡ï¼Œä»…ç”¨äºæ¼”ç¤º
                tokens = len(outputs["thinking"]) // 4
                self.total_tokens += tokens
    
    def on_chain_error(self, error: Exception, **kwargs):
        """å½“é“¾/èŠ‚ç‚¹æ‰§è¡Œå‡ºé”™æ—¶è°ƒç”¨
        
        WHY: éœ€è¦æ•è·å’Œè®°å½•é”™è¯¯ä¿¡æ¯ï¼Œä¾¿äºè°ƒè¯•å’Œé”™è¯¯å¤„ç†
        HOW: è·å–èŠ‚ç‚¹åç§°å’Œé”™è¯¯è¯¦æƒ…ï¼Œæ ¼å¼åŒ–è¾“å‡º
        WHAT: æä¾›é”™è¯¯è·Ÿè¸ªå’Œè¯Šæ–­ä¿¡æ¯
        """
        # ä»kwargsä¸­è·å–åºåˆ—åŒ–ä¿¡æ¯
        serialized = kwargs.get("serialized", {})
        node_name = serialized.get("name", "unknown")
        
        print(f"!! é”™è¯¯: {node_name} - {str(error)}")
    
    def get_summary(self):
        """è·å–æ‰§è¡Œæ‘˜è¦
        
        WHY: éœ€è¦ä¸€ç§æ–¹å¼æ±‡æ€»å’Œå‘ˆç°æ‰€æ”¶é›†çš„æ‰€æœ‰æ‰§è¡ŒæŒ‡æ ‡
        HOW: æ•´åˆå„ç±»ç»Ÿè®¡æ•°æ®ï¼Œæ„å»ºæ‘˜è¦å­—å…¸
        WHAT: æä¾›å®Œæ•´çš„æ‰§è¡Œæ€§èƒ½å’Œè¡Œä¸ºæ¦‚è§ˆ
        """
        return {
            "steps": self.steps,
            "node_times": self.node_times,
            "total_tokens": self.total_tokens
        }

def create_callback_handlers():
    """åˆ›å»ºå›è°ƒå¤„ç†å™¨å®ä¾‹
    
    WHY - è®¾è®¡æ€è·¯:
    1. éœ€è¦å°è£…å›è°ƒå¤„ç†å™¨çš„åˆ›å»ºé€»è¾‘ï¼Œä¾¿äºå¤ç”¨
    2. å¯èƒ½éœ€è¦åœ¨åˆ›å»ºæ—¶è¿›è¡Œé…ç½®æˆ–è‡ªå®šä¹‰
    3. å°†åˆ›å»ºä¸ä½¿ç”¨åˆ†ç¦»ï¼Œç¬¦åˆå•ä¸€èŒè´£åŸåˆ™
    
    HOW - å®ç°æ–¹å¼:
    åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªé…ç½®å¥½çš„CustomCallbackHandlerå®ä¾‹
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æä¾›ä¸€ä¸ªå·¥å‚å‡½æ•°ï¼Œç”¨äºåˆ›å»ºå‡†å¤‡å°±ç»ªçš„å›è°ƒå¤„ç†å™¨
    """
    return CustomCallbackHandler()

def format_prompt_from_messages(messages: List[BaseMessage]) -> str:
    """ä»æ¶ˆæ¯åˆ—è¡¨æ ¼å¼åŒ–æç¤ºå­—ç¬¦ä¸²
    
    WHY - è®¾è®¡æ€è·¯:
    1. LLMçš„streamæ–¹æ³•ç›´æ¥æ¥å—å­—ç¬¦ä¸²æç¤ºï¼Œè€Œä¸æ˜¯æ¶ˆæ¯åˆ—è¡¨
    2. éœ€è¦å°†ç»“æ„åŒ–æ¶ˆæ¯è½¬æ¢ä¸ºé€‚åˆLLMå¤„ç†çš„æ–‡æœ¬æ ¼å¼
    3. æ ¼å¼éœ€è¦ä¿æŒä¸€è‡´ï¼Œç¡®ä¿LLMç†è§£æ¶ˆæ¯çš„è§’è‰²å’Œå†…å®¹
    
    HOW - å®ç°æ–¹å¼:
    1. éå†æ¶ˆæ¯åˆ—è¡¨
    2. æ ¹æ®æ¶ˆæ¯ç±»å‹æ·»åŠ å¯¹åº”çš„å‰ç¼€ï¼ˆå¦‚"ç³»ç»Ÿï¼š"ã€"ç”¨æˆ·ï¼š"ã€"AIï¼š"ï¼‰
    3. æ‹¼æ¥æ‰€æœ‰æ ¼å¼åŒ–çš„æ¶ˆæ¯
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    å°†LangChainæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºLLMå¯ç›´æ¥å¤„ç†çš„æ–‡æœ¬æç¤ºï¼Œ
    ä¿ç•™æ¶ˆæ¯çš„è§’è‰²ä¿¡æ¯
    """
    formatted_prompt = ""
    for message in messages:
        if isinstance(message, SystemMessage):
            formatted_prompt += f"ç³»ç»Ÿ: {message.content}\n\n"
        elif isinstance(message, HumanMessage):
            formatted_prompt += f"ç”¨æˆ·: {message.content}\n\n"
        elif isinstance(message, AIMessage):
            formatted_prompt += f"AI: {message.content}\n\n"
    
    # æ·»åŠ æœ€åçš„AIå‰ç¼€ï¼Œå¼•å¯¼æ¨¡å‹å¼€å§‹å›å¤
    formatted_prompt += "AI: "
    return formatted_prompt

def run_callback_example():
    """è¿è¡Œå¸¦å›è°ƒçš„æµå¼å¤„ç†ç¤ºä¾‹
    
    WHY - è®¾è®¡æ€è·¯:
    1. å®é™…åº”ç”¨ä¸­å¸¸éœ€è¦è·Ÿè¸ªæ‰§è¡Œè¿‡ç¨‹çš„è¯¦ç»†ä¿¡æ¯å’Œç»Ÿè®¡æ•°æ®
    2. ç”¨æˆ·éœ€è¦äº†è§£å›è°ƒç³»ç»Ÿå¦‚ä½•å·¥ä½œä»¥åŠå¦‚ä½•æ”¶é›†è‡ªå®šä¹‰æŒ‡æ ‡
    3. å›è°ƒå¯ä»¥ç”¨äºæ€§èƒ½åˆ†æã€ç›‘æ§å’Œè°ƒè¯•
    
    HOW - å®ç°æ–¹å¼:
    1. åˆ›å»ºè‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨ï¼Œå®ç°å…³é”®å›è°ƒæ–¹æ³•
    2. å‡†å¤‡å›¾å’Œåˆå§‹çŠ¶æ€
    3. åœ¨é…ç½®ä¸­æ·»åŠ å›è°ƒå¤„ç†å™¨
    4. ä½¿ç”¨æ™®é€šinvokeæ–¹æ³•æ‰§è¡Œå›¾ï¼ˆå›è°ƒä»ç„¶æœ‰æ•ˆï¼‰
    5. ä»å›è°ƒå¤„ç†å™¨æ”¶é›†æ‰§è¡Œæ‘˜è¦å¹¶æ˜¾ç¤º
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å›è°ƒç³»ç»Ÿç›‘æ§å’Œåˆ†æLangGraphæ‰§è¡Œè¿‡ç¨‹ï¼Œ
    æ”¶é›†æ‰§è¡Œæ­¥éª¤ã€è€—æ—¶ã€tokenä½¿ç”¨ç­‰å…³é”®æŒ‡æ ‡
    """
    print("\n===== äº‹ä»¶ç›‘å¬ä¸å›è°ƒç¤ºä¾‹ =====")
    
    # åˆ›å»ºå›¾
    graph = create_basic_graph()
    
    # åˆå§‹åŒ–çŠ¶æ€
    state = initialize_state()
    state["messages"].append(HumanMessage(content="ä»‹ç»äººå·¥æ™ºèƒ½çš„å†å²å’Œæœªæ¥å‘å±•è¶‹åŠ¿"))
    
    # åˆ›å»ºå›è°ƒå¤„ç†å™¨
    callback_handler = create_callback_handlers()
    
    # é…ç½®
    config = {
        "recursion_limit": 25,
        "callbacks": [callback_handler]  # æ·»åŠ å›è°ƒå¤„ç†å™¨
    }
    
    print("\nå¼€å§‹æ‰§è¡Œæµç¨‹ï¼Œå¸¦äº‹ä»¶ç›‘å¬...")
    
    # æ‰§è¡Œå›¾
    result = graph.invoke(state, config)
    
    # æ‰“å°æ‘˜è¦
    print("\n===== æ‰§è¡Œæ‘˜è¦ =====")
    summary = callback_handler.get_summary()
    print(f"æ‰§è¡Œæ­¥éª¤: {summary['steps']}")
    print(f"æ€»tokenæ•°: {summary['total_tokens']}")
    print("èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´:")
    for node, time_taken in summary['node_times'].items():
        print(f"  - {node}: {time_taken:.2f}ç§’")
    
    # è¿”å›å“åº”
    if result and "messages" in result and result["messages"]:
        print("\næœ€ç»ˆå›å¤:")
        print(result["messages"][-1].content)

# ===========================================================
# ç¬¬9éƒ¨åˆ†: æ‰§è¡Œç¤ºä¾‹
# ===========================================================

if __name__ == "__main__":
    """ä¸»å‡½æ•° - æ‰§è¡Œæ‰€æœ‰æµå¼å¤„ç†ç¤ºä¾‹
    
    WHY - è®¾è®¡æ€è·¯:
    1. éœ€è¦ä¸€ä¸ªç»Ÿä¸€çš„å…¥å£ç‚¹æ¥å±•ç¤ºæ‰€æœ‰æµå¼å¤„ç†ç¤ºä¾‹
    2. éœ€è¦ä»¥ä¸€ç§æœ‰ç»„ç»‡çš„æ–¹å¼å‘ˆç°ä¸åŒç±»å‹çš„æµå¼å¤„ç†æ¨¡å¼
    3. æ–¹ä¾¿ç”¨æˆ·ç†è§£ä¸åŒç¤ºä¾‹ä¹‹é—´çš„åŒºåˆ«å’Œåº”ç”¨åœºæ™¯
    
    HOW - å®ç°æ–¹å¼:
    1. ä¾æ¬¡è°ƒç”¨å„ä¸ªç¤ºä¾‹å‡½æ•°ï¼Œå…ˆä»åŸºç¡€ç¤ºä¾‹å¼€å§‹
    2. æ¯ä¸ªç¤ºä¾‹ä¹‹é—´æ·»åŠ åˆ†éš”ç¬¦å’Œæš‚åœï¼Œä¾¿äºè§‚å¯Ÿ
    3. æ•è·å¯èƒ½çš„å¼‚å¸¸ï¼Œç¡®ä¿ä¸€ä¸ªç¤ºä¾‹çš„å¤±è´¥ä¸ä¼šå½±å“å…¶ä»–ç¤ºä¾‹
    
    WHAT - åŠŸèƒ½ä½œç”¨:
    æä¾›ä¸€ä¸ªå®Œæ•´çš„æµå¼å¤„ç†æŠ€æœ¯æ¼”ç¤ºï¼Œå±•ç¤ºLangGraphä¸­
    ä»ç®€å•åˆ°å¤æ‚çš„å„ç§æµå¼å¤„ç†èƒ½åŠ›å’Œåº”ç”¨æ–¹å¼
    """
    print("===== LangGraph æµå¼å¤„ç†ä¸å®æ—¶åé¦ˆç¤ºä¾‹ =====\n")
    
    try:
        # 1. è¿è¡ŒåŸºæœ¬æµå¼å¤„ç†ç¤ºä¾‹
        run_basic_stream_example()
        input("\næŒ‰Enterç»§ç»­ä¸‹ä¸€ä¸ªç¤ºä¾‹...")
        
        # 2. è¿è¡Œé«˜çº§æµå¼å¤„ç†ç¤ºä¾‹
        run_advanced_stream_example()
        input("\næŒ‰Enterç»§ç»­ä¸‹ä¸€ä¸ªç¤ºä¾‹...")
        
        # 3. è¿è¡Œå­—ç¬¦çº§æµå¼è¾“å‡ºç¤ºä¾‹
        run_character_stream_example()
        input("\næŒ‰Enterç»§ç»­ä¸‹ä¸€ä¸ªç¤ºä¾‹...")
        
        # 4. è¿è¡Œäº‹ä»¶ç›‘å¬ä¸å›è°ƒç¤ºä¾‹
        run_callback_example()
        
        print("\n===== æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæ¯• =====")
        print("é€šè¿‡è¿™äº›ç¤ºä¾‹ï¼Œæ‚¨åº”è¯¥å·²ç»äº†è§£äº†LangGraphä¸­çš„å„ç§æµå¼å¤„ç†æ–¹å¼")
        print("ä»åŸºæœ¬çŠ¶æ€æµã€äº‹ä»¶æµã€åˆ°å­—ç¬¦çº§æµå’Œå›è°ƒç›‘æ§ï¼Œå¯ä»¥æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ–¹å¼")
        
    except Exception as e:
        print(f"\næ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc() 